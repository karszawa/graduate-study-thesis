# 分散システム

分散システムは、通信ネットワークにより結合された複数のプロセス上で、共通の目的の計算をするためのシステムである。
分散システムは通常は複数のコンピュータを用いて構成されるため、物理的な共有メモリを持たない。
さらにプロセス間のメッセージ通信には遅延があり、それがどれほどの大きさかもわからない。
したがって2つのプロセスでそれぞれ実行されたイベントは、それらが同一メッセージの送信イベントと受信イベントでなければ、
どちらが物理的に先に実行されたものなのかは区別できない。
ここでいうイベントとは、プロセスが行う意味的にまとまった処理のことを指し、
たとえば、関数の局所計算やプロセス間を行き交うメッセージの送信・受信などが当てはまる。

このようなモデルを用いる利点は以下のとおりである。

- 負荷分散、機能分散により処理を高速化できる。
- システムを構成しているいくつかのコンピュータが故障してもシステム全体で処理を継続できる。
- 複数の低価格なコンピュータでシステムを構成するため、低コストである。
- コンピュータの追加、削除を容易に行えるため拡張性が高い。

## 同期システムと非同期システム

分散システムは、プロセスの実行速度、通信遅延、局所時計の非同期性の程度によって、同期システムと非同期システムに大別される。
以下の3つの条件を満たす分散システムを同期システムと呼ぶ\cite{da}。

- プロセスの実行速度(単位時間あたり実行される命令の数)に定数の下限が存在する。
- 通信にかかる通信遅延に定数の上限が存在する。
- 分散システム全体に共通して流れる時間において、すべてのプロセス$P_i$の局所時計の値$clock_i$は等しい。

これらの条件を1つでも満たさない分散システムが非同期システムであるが、その非同期さには程度の差が大きく、特に以下の3つの条件を満たす非同期システムを完全非同期システムと呼ぶ。

- プロセスの実行速度に対してどのような仮定も設けない。ただし、あるプロセスがある命令を実行しようとしたときには、有限時間内にその命令が実行されることだけは仮定する。
- 通信遅延に対してどのような仮定も設けない。ただし通信遅延は有限である。
- 局所時計の差に対してどのような仮定も設けない。ただし、局所時間の修正は可能である。

分散システムが実現される通信ネットワークは様々であり、同期システムの条件を仮定することは難しいので、本研究では分散システムを完全非同期システムでない非同期システムと仮定している。

<!-- H-DASの非同期さの度合いについて明示したほうが良い -->
<!--
H-DASの分散システムの非同期さは以下のように特徴づけられると思う。

- プロセスの実行速度は通信遅延のあるメッセージ送配に対して非常に高速だと仮定し、ユーザが指定したイベントは瞬時に実行開始し、終了する(ユーザが指定しないイベントは指定されるまで実行されない)。
- 通信にかかる通信遅延に定数の上限が存在する。
- 局所時計の差に対してどのような仮定も設けない。ただし、局所時間の修正は可能である。

この理解は正しいか？
-->

## 分散計算のモデル

分散計算は分散システム上で生起するイベントの集合としてモデル化できる。
イベントの集合には順序関係が定義され、その関係の種類により分散計算のモデルは以下の3つに分けられる。

Interleaving Model

: 分散システム上で生起するすべてのイベントの間に全順序が定まる。

Happend Before Model

: 異なるプロセスで生起するすべてのイベントの間に半順序が、同一のプロセスで生起するすべてのイベントの間に全順序が定まる。

Potential Causality Model

: 分散システム上で生起するすべてのイベントの間に半順序が定まる。

H-DASではInterleaving Modelを採用している。
Happend Before ModelやPotential Causality Modelの分散計算もInterleaving Modelを用いて実現可能である。
なぜなら、Happened Before Modelの1つの計算結果は有限個のInterleaving Modelによる計算結果と等価であり、
Potential Causality Modelの1つの計算結果は有限個のHappened Before Modelによる計算結果と等価であるからである。

<!-- 等価な理由が謎、あとInterleaving Modelがユーザにどう関係するのか明示するべき -->

# 分散アルゴリズム

分散アルゴリズムは、ある共通の目的を達成するために分散システム上のプロセスが行う計算の手順を定めたものである。
分散システムには共有メモリが存在しないため、アルゴリズム実行開始直後の各プロセスは自身の局所情報しか知ることができない。
そのため分散アルゴリズムでは、各プロセスがメッセージの送受信により互いの情報を交換することで処理を進める。

分散アルゴリズムを実行中のプロセスの状態は、命令を実行中の実行状態と、他のプロセスからのメッセージを待っている待機状態の2つに分けられる。
分散アルゴリズムの実行は、1つ以上のプロセスが自発的に処理を始めることによって開始される。
自発的に処理を始めるプロセスのこと始動プロセスという。
始動プロセス以外のプロセスは他のプロセスからのメッセージを受け取ってからアルゴリズムの実行を開始する。

## 分散アルゴリズムの評価

分散アルゴリズムの性能を評価するための尺度として、通信複雑度と時間複雑度がある。
アルゴリズムの実行開始から実行終了までにプロセスの間で交換されたすべてのメッセージの総和をメッセージ複雑度といい、
プロセス間で交換されるメッセージに含まれるすべてのビット数の総和をビット複雑度という。
両者を合わせて通信複雑度という\cite{da}。
時間複雑度は実行開始から実行停止までに生じたメッセージの最長鎖に属するメッセージの総数である。
ここで鎖とは最初のメッセージを除く他のすべてのメッセージが直前のメッセージの受信によって生じたようなメッセージ列のことをいう。

良い分散アルゴリズムであればあるほど、問題を解決するために必要な情報を効率的に交換していると予想されるので、
通信複雑度がアルゴリズムの良さの尺度として適切であることがわかる。

アルゴリズムの実行速度も評価のための重要な尺度である。
逐次アルゴリズム(分散アルゴリズムでない普通のアルゴリズム)ならば、アルゴリズムの実行速度はアルゴリズムが終了するまでの基本演算の数によって評価できる。
しかし、分散アルゴリズムではプロセスが他のプロセスからのメッセージを待つ状態にあることも多く、単純に基本演算の数で実行速度を評価することはできない。
そこで考えだされたのが時間複雑度である。
時間複雑度は、プロセスが一度に可能なかぎりのメッセージを送信するという仮定のもとで、アルゴリズムの実行時間の評価とみなすことができる。

## 論理時計

分散システムを構成する複数のコンピュータは共有時計を持たない。
そのため、システム上で生起したイベントの発生順をとらえるには工夫が必要となる。
そこで、各イベントに整数あるいは整数のベクトルで表現される時刻印を付与し、それをイベントの発生順序の判別に用いる。
それが論理時計である。

論理時計には様々な種類が存在するが、H-DASではDirect-Dependency Clockを用いている。
この時計を用いる場合、プロセスは通信のたびにメッセージにただ1つの整数だけを付与するため、通信パケットの大きさがほとんど変化しない。
以下にDirect-Dependency ClockのアルゴリズムをJava言語により記述する。

<!-- https://books.google.co.jp/books?id=2pKCnc6-UAEC -->

\begin{lstlisting}[language=Java, caption=Direct Dependency Clock]
public class DirectDependencyClock {
	public int[] clock;
	int myId;
	
	public DirectDependencyClock(int numberOfProcess, int id) {
		myId = id;
		clock = new int[numberOfProcess];
	
		for (int i = 0; i < numProc; i++) {
			clock[i] = 0;
		}
		
		clock[myId] = 1;
	}
	
	// internal action
	public void tick() {
		clock[myId]++;
	}
	
	public void sendAction() {
		// sentValue = clock[myId];
		tick();
	}
	
	public void receiveAction(int sender, int sentValue) {
		clock[sender] = Util.max(clock[sender], sentValue);
		clock[myId] = Util.max(clock[myId], sentValue) + 1;
	}		
}
\end{lstlisting}

論理時計にDirect-Dependency Clockを用いるならば、プロセスのクラスはDirectDependencyClockクラスをメンバに持つことになる。
この時計を用いるとき、状態$s$にあるプロセス$P_i$と状態$t$にあるプロセス$P_j$を考え、状態$t$は状態$s$より因果的に後の状態なのかどうかを知りたければ、
$P_i$の時計を$clock_i$、$P_j$の時計を$clock_j$とし、$clock_i[i] \le clock_j[i]$が成り立つかどうかを見れば良い。
もちろん、状態$s$が状態$t$より因果的に後の状態なのであれば、$clock_j[j] \le clock_i[j]$が成り立つ。
どちらも成り立たないというときは状態$s$と状態$t$は因果的に関係ない状態ということである。

<!-- わかりにくい -->

図\ref{fig:direct-dependency-clock}はDirect Dependency Clockの実行例である。
実際に、$s_0$の後に$s_3$の状態になっているので、$clock_0[0] \le clock_1[0]$が成り立っている。
どちらが因果的に先に生じたともいえない$s_2$と$s_3$では、$clock_2[2] \le clock_1[2]$も$clock_1[1] \le clock_2[1]$も成り立たない。

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\linewidth]{./src/fig/direct-dependency-clock.eps}
	\caption{Direct-Dependency Clockの実行例 \label{fig:direct-dependency-clock}}
\end{figure}

## コータリー

分散システム上の複数のプロセスがある1つの資源を占有的に使用したいと同時に望むとき、
資源を使用できるプロセスをただ1つに決定しなければならない。
このような問題を相互排除と呼ぶ。
コータリーは純粋に数学的な概念だが、分散アルゴリズムではこれを相互排除のために使う。

Uをプロセスの集合とし、以下の2条件を満たすUの部分集合$Q_i$(コーラムと呼ばれる)の集合をコータリーと呼ぶ。

1. すべての対$i$と$j(1 \leq i,j \leq N)$に対して、$Q_i \cap Q_j \neq \theta$
2. すべての対$i$と$j(1 \leq i,j \leq N, i \neq j)$に対して、$Q_i \nsubseteq Q_j$

コータリー$C$を用いた相互排除では、プロセスはあるコーラム$Q \in C$に含まれるすべてのプロセスから資源の使用許可を得る必要がある。
$C$に含まれるすべての2つのコーラムは少なくとも1つのプロセスを共有するので、プロセスが複数のプロセスに同時に資源使用の許可を与えるということがなければ、
常にただ1つのプロセスだけが資源を使用できるようにできる。

コータリーに基づく相互排除のアルゴリズムは耐故障性に優れている。
通信ネットワークが完全グラフで、通信リンクが絶対に故障しないような理想的な分散システムでは、
少なくともコーラムに属するすべてのプロセスが正常であるならば相互排除のアルゴリズムは正常に動作する。

H-DASではMajority、Singleton、Crumbling Wall Logの3つのコータリーを使用できる。
